{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./../clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.columns[1:]\n",
    "x=df.loc[:,labels]\n",
    "y=df.loc[:,'churn']\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution after oversampling:\n",
      "churn\n",
      "No     3269\n",
      "Yes    3269\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution after undersampling:\n",
      "churn\n",
      "No     3269\n",
      "Yes    3269\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(xtrain, ytrain)\n",
    "\n",
    "# Display class distribution after oversampling\n",
    "print(\"\\nClass distribution after oversampling:\")\n",
    "print(pd.Series(y_resampled).value_counts())\n",
    "\n",
    "# Apply RandomUnderSampler to address class imbalance\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "#X_resampled, y_resampled = rus.fit_resample(xtrain, ytrain)\n",
    "\n",
    "# Display class distribution after undersampling\n",
    "print(\"\\nClass distribution after undersampling:\")\n",
    "print(pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 486 candidates, totalling 2430 fits\n",
      "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 16, 'hidden_layer_sizes': (100,), 'learning_rate': 'adaptive', 'max_iter': 9999999999, 'solver': 'adam'}\n",
      "Fitting 5 folds for each of 486 candidates, totalling 2430 fits\n",
      "{'activation': 'relu', 'alpha': 0.0001, 'batch_size': 16, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'max_iter': 9999999999, 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'hidden_layer_sizes': [(100,), (50, 50), (25, 25, 25)],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'solver': ['adam', 'sgd', 'lbfgs'],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'max_iter': [9999999999]\n",
    "    }\n",
    "\n",
    "clf_accuracy = GridSearchCV(estimator=MLPClassifier(),param_grid=params,cv=5,n_jobs=5,verbose=1,scoring='accuracy')\n",
    "clf_accuracy.fit(xtrain,ytrain)\n",
    "\n",
    "print(clf_accuracy.best_params_)\n",
    "model_accuracy = MLPClassifier(**clf_accuracy.best_params_) \n",
    "\n",
    "f1 = sklearn.metrics.make_scorer(sklearn.metrics.f1_score, average='micro')\n",
    "\n",
    "clf_f1 = GridSearchCV(estimator=MLPClassifier(),param_grid=params,cv=5,n_jobs=5,verbose=1,scoring=f1)\n",
    "clf_f1.fit(xtrain,ytrain)\n",
    "\n",
    "print(clf_f1.best_params_)\n",
    "modelf1 = MLPClassifier(**clf_f1.best_params_) \n",
    "\n",
    "combi_model = VotingClassifier(estimators=[('acc', model_accuracy), ('f1', modelf1)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy = MLPClassifier(activation= 'relu', alpha= 0.0001, batch_size= 16, hidden_layer_sizes= (100,), learning_rate= 'adaptive', max_iter= 9999999999, solver= 'adam') \n",
    "modelf1 = MLPClassifier(activation= 'relu', alpha= 0.0001, batch_size= 16, hidden_layer_sizes= (100,), learning_rate= 'constant', max_iter= 9999999999, solver= 'adam') \n",
    "\n",
    "combi_model = VotingClassifier(estimators=[('acc', model_accuracy), ('f1', modelf1)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.95253165 0.95886076 0.96518987 0.94614572 0.94825766]\n",
      "Mean Accuracy: 0.9541971315145762\n",
      "Standard Deviation: 0.007006656689921636\n"
     ]
    }
   ],
   "source": [
    "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_scores = cross_val_score(model_accuracy, x, y, cv=cv_strategy, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "print(\"Mean Accuracy:\", cross_val_scores.mean())\n",
    "print(\"Standard Deviation:\", cross_val_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced model\n",
      "accuracy: 0.9177215189873418\n",
      "recall: 0.76\n",
      "precision: 0.6643356643356644\n",
      "f1: 0.7089552238805971\n",
      "confusion matrix:\n",
      "[[775  48]\n",
      " [ 30  95]]\n",
      "\n",
      "f1 model\n",
      "accuracy: 0.919831223628692\n",
      "recall: 0.648\n",
      "precision: 0.7168141592920354\n",
      "f1: 0.680672268907563\n",
      "confusion matrix:\n",
      "[[791  32]\n",
      " [ 44  81]]\n",
      "\n",
      "combination model\n",
      "accuracy: 0.9113924050632911\n",
      "recall: 0.736\n",
      "precision: 0.6433566433566433\n",
      "f1: 0.6865671641791045\n",
      "confusion matrix:\n",
      "[[772  51]\n",
      " [ 33  92]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_accuracy.fit(X_resampled,y_resampled)\n",
    "\n",
    "yhat = model_accuracy.predict(xtest)\n",
    "\n",
    "acc = sklearn.metrics.accuracy_score(ytest,yhat)\n",
    "recall = sklearn.metrics.recall_score(ytest,yhat,pos_label='Yes')\n",
    "prec = sklearn.metrics.precision_score(ytest,yhat,pos_label='Yes')\n",
    "f1 = sklearn.metrics.f1_score(ytest,yhat,pos_label='Yes')\n",
    "conf_matrix =  sklearn.metrics.confusion_matrix(ytest,yhat)\n",
    "print('balanced model')\n",
    "print(f\"accuracy: {acc}\")\n",
    "print(f\"recall: {recall}\")\n",
    "print(f\"precision: {prec}\")\n",
    "print(f\"f1: {f1}\")\n",
    "print(f\"confusion matrix:\\n{conf_matrix}\\n\")\n",
    "\n",
    "modelf1.fit(X_resampled,y_resampled)\n",
    "\n",
    "yhat = modelf1.predict(xtest)\n",
    "\n",
    "acc = sklearn.metrics.accuracy_score(ytest,yhat)\n",
    "recall = sklearn.metrics.recall_score(ytest,yhat,pos_label='Yes')\n",
    "prec = sklearn.metrics.precision_score(ytest,yhat,pos_label='Yes')\n",
    "f1 = sklearn.metrics.f1_score(ytest,yhat,pos_label='Yes')\n",
    "conf_matrix =  sklearn.metrics.confusion_matrix(ytest,yhat)\n",
    "print('f1 model')\n",
    "print(f\"accuracy: {acc}\")\n",
    "print(f\"recall: {recall}\")\n",
    "print(f\"precision: {prec}\")\n",
    "print(f\"f1: {f1}\")\n",
    "print(f\"confusion matrix:\\n{conf_matrix}\\n\")\n",
    "\n",
    "combi_model.fit(X_resampled,y_resampled)\n",
    "\n",
    "yhat = combi_model.predict(xtest)\n",
    "\n",
    "acc = sklearn.metrics.accuracy_score(ytest,yhat)\n",
    "recall = sklearn.metrics.recall_score(ytest,yhat,pos_label='Yes')\n",
    "prec = sklearn.metrics.precision_score(ytest,yhat,pos_label='Yes')\n",
    "f1 = sklearn.metrics.f1_score(ytest,yhat,pos_label='Yes')\n",
    "conf_matrix =  sklearn.metrics.confusion_matrix(ytest,yhat)\n",
    "print('combination model')\n",
    "print(f\"accuracy: {acc}\")\n",
    "print(f\"recall: {recall}\")\n",
    "print(f\"precision: {prec}\")\n",
    "print(f\"f1: {f1}\")\n",
    "print(f\"confusion matrix:\\n{conf_matrix}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
