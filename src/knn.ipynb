{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./../clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.columns[1:]\n",
    "x=df.loc[:,labels]\n",
    "y=df.loc[:,'churn']\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution after oversampling:\n",
      "churn\n",
      "No     3277\n",
      "Yes    3277\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution after undersampling:\n",
      "churn\n",
      "No     513\n",
      "Yes    513\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(xtrain, ytrain)\n",
    "\n",
    "# Display class distribution after oversampling\n",
    "print(\"\\nClass distribution after oversampling:\")\n",
    "print(pd.Series(y_resampled).value_counts())\n",
    "\n",
    "# Apply RandomUnderSampler to address class imbalance\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(xtrain, ytrain)\n",
    "\n",
    "# Display class distribution after undersampling\n",
    "print(\"\\nClass distribution after undersampling:\")\n",
    "print(pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "results= [['name','accuracy','recall','prec','f1']]\n",
    "def evaluate_model(model,name,X_test,y_test,dec_number):\n",
    "    yhat = model.predict(X_test)\n",
    "\n",
    "    acc = round(sklearn.metrics.accuracy_score(y_test,yhat),dec_number)\n",
    "    recall = round(sklearn.metrics.recall_score(y_test,yhat,pos_label='Yes'),dec_number)\n",
    "    prec = round(sklearn.metrics.precision_score(y_test,yhat,pos_label='Yes'),dec_number)\n",
    "    f1 = round(sklearn.metrics.f1_score(y_test,yhat,pos_label='Yes'),dec_number)\n",
    "\n",
    "    results.append([name,acc,recall,prec,f1])\n",
    "    \n",
    "    \n",
    "def print_results(results):\n",
    "    # Print each row\n",
    "    for row in results:\n",
    "        row_str = \" | \".join(str(element) for element in row)\n",
    "        print(row_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n",
      "{'algorithm': 'ball_tree', 'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n",
      "{'algorithm': 'ball_tree', 'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_neighbors': [3,5,7,9,11,13],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm' : ['ball_tree', 'kd_tree', 'brute'],\n",
    "    'p' : [1,2,3,4,5]\n",
    "    }\n",
    "\n",
    "\n",
    "clf_accuracy = GridSearchCV(estimator=KNeighborsClassifier(),param_grid=params,cv=5,n_jobs=10,verbose=1,scoring='accuracy')\n",
    "clf_accuracy.fit(xtrain,ytrain)\n",
    "\n",
    "print(clf_accuracy.best_params_)\n",
    "model_accuracy = KNeighborsClassifier(**clf_accuracy.best_params_) \n",
    "\n",
    "f1 = sklearn.metrics.make_scorer(sklearn.metrics.f1_score, average='micro')\n",
    "\n",
    "clf_f1 = GridSearchCV(estimator=KNeighborsClassifier(),param_grid=params,cv=5,n_jobs=5,verbose=1,scoring=f1)\n",
    "clf_f1.fit(xtrain,ytrain)\n",
    "\n",
    "print(clf_f1.best_params_)\n",
    "modelf1 = KNeighborsClassifier(n_neighbors=clf_f1.best_params_['n_neighbors'], weights=clf_f1.best_params_['weights'], algorithm=clf_f1.best_params_['algorithm'], p=clf_f1.best_params_['p']) \n",
    "\n",
    "combi_model = VotingClassifier(estimators=[('acc', model_accuracy), ('f1', modelf1)], voting='soft')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [0.89556962 0.90400844 0.90506329 0.89545935 0.90813094]\n",
      "Mean Accuracy: 0.9016463270643694\n",
      "Standard Deviation: 0.005186723954450055\n"
     ]
    }
   ],
   "source": [
    "cv_strategy = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cross_val_scores = cross_val_score(model_accuracy, x, y, cv=cv_strategy, scoring='accuracy')\n",
    "\n",
    "print(\"Cross-Validation Scores:\", cross_val_scores)\n",
    "print(\"Mean Accuracy:\", cross_val_scores.mean())\n",
    "print(\"Standard Deviation:\", cross_val_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced model\n",
      "accuracy: 0.8185654008438819\n",
      "recall: 0.7819548872180451\n",
      "precision: 0.42105263157894735\n",
      "f1: 0.5473684210526316\n",
      "confusion matrix:\n",
      "[[672 143]\n",
      " [ 29 104]]\n",
      "\n",
      "f1 model\n",
      "accuracy: 0.8185654008438819\n",
      "recall: 0.7819548872180451\n",
      "precision: 0.42105263157894735\n",
      "f1: 0.5473684210526316\n",
      "confusion matrix:\n",
      "[[672 143]\n",
      " [ 29 104]]\n",
      "\n",
      "combination model\n",
      "accuracy: 0.8185654008438819\n",
      "recall: 0.7819548872180451\n",
      "precision: 0.42105263157894735\n",
      "f1: 0.5473684210526316\n",
      "confusion matrix:\n",
      "[[672 143]\n",
      " [ 29 104]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_accuracy.fit(X_resampled,y_resampled)\n",
    "\n",
    "yhat = model_accuracy.predict(xtest)\n",
    "\n",
    "acc = sklearn.metrics.accuracy_score(ytest,yhat)\n",
    "recall = sklearn.metrics.recall_score(ytest,yhat,pos_label='Yes')\n",
    "prec = sklearn.metrics.precision_score(ytest,yhat,pos_label='Yes')\n",
    "f1 = sklearn.metrics.f1_score(ytest,yhat,pos_label='Yes')\n",
    "conf_matrix =  sklearn.metrics.confusion_matrix(ytest,yhat)\n",
    "print('balanced model')\n",
    "print(f\"accuracy: {acc}\")\n",
    "print(f\"recall: {recall}\")\n",
    "print(f\"precision: {prec}\")\n",
    "print(f\"f1: {f1}\")\n",
    "print(f\"confusion matrix:\\n{conf_matrix}\\n\")\n",
    "\n",
    "modelf1.fit(X_resampled,y_resampled)\n",
    "\n",
    "yhat = modelf1.predict(xtest)\n",
    "\n",
    "acc = sklearn.metrics.accuracy_score(ytest,yhat)\n",
    "recall = sklearn.metrics.recall_score(ytest,yhat,pos_label='Yes')\n",
    "prec = sklearn.metrics.precision_score(ytest,yhat,pos_label='Yes')\n",
    "f1 = sklearn.metrics.f1_score(ytest,yhat,pos_label='Yes')\n",
    "conf_matrix =  sklearn.metrics.confusion_matrix(ytest,yhat)\n",
    "print('f1 model')\n",
    "print(f\"accuracy: {acc}\")\n",
    "print(f\"recall: {recall}\")\n",
    "print(f\"precision: {prec}\")\n",
    "print(f\"f1: {f1}\")\n",
    "print(f\"confusion matrix:\\n{conf_matrix}\\n\")\n",
    "\n",
    "combi_model.fit(X_resampled,y_resampled)\n",
    "\n",
    "yhat = combi_model.predict(xtest)\n",
    "\n",
    "acc = sklearn.metrics.accuracy_score(ytest,yhat)\n",
    "recall = sklearn.metrics.recall_score(ytest,yhat,pos_label='Yes')\n",
    "prec = sklearn.metrics.precision_score(ytest,yhat,pos_label='Yes')\n",
    "f1 = sklearn.metrics.f1_score(ytest,yhat,pos_label='Yes')\n",
    "conf_matrix =  sklearn.metrics.confusion_matrix(ytest,yhat)\n",
    "print('combination model')\n",
    "print(f\"accuracy: {acc}\")\n",
    "print(f\"recall: {recall}\")\n",
    "print(f\"precision: {prec}\")\n",
    "print(f\"f1: {f1}\")\n",
    "print(f\"confusion matrix:\\n{conf_matrix}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name | accuracy | recall | prec | f1\n",
      "model | 0.819 | 0.782 | 0.421 | 0.547\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_accuracy,'model',xtest,ytest,3)\n",
    "print_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
