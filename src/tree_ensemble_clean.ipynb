{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.11/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:15: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, make_scorer, f1_score, precision_score, recall_score\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution after oversampling:\n",
      "No     3273\n",
      "Yes    3273\n",
      "Name: churn, dtype: int64\n",
      "\n",
      "Class distribution after undersampling:\n",
      "No     519\n",
      "Yes    519\n",
      "Name: churn, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accountlength</th>\n",
       "      <th>numbervmailmessages</th>\n",
       "      <th>totaldayminutes</th>\n",
       "      <th>totaldaycalls</th>\n",
       "      <th>totalevecalls</th>\n",
       "      <th>totalevecharge</th>\n",
       "      <th>totalnightminutes</th>\n",
       "      <th>totalnightcalls</th>\n",
       "      <th>totalintlcalls</th>\n",
       "      <th>totalintlcharge</th>\n",
       "      <th>numbercustomerservicecalls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.384259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.537786</td>\n",
       "      <td>0.396552</td>\n",
       "      <td>0.658120</td>\n",
       "      <td>0.890114</td>\n",
       "      <td>0.657114</td>\n",
       "      <td>0.316239</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.270455</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.459605</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.541863</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.119732</td>\n",
       "      <td>0.597468</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.515909</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.532407</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.732204</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.675214</td>\n",
       "      <td>0.287909</td>\n",
       "      <td>0.758747</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.595455</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.661963</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.470085</td>\n",
       "      <td>0.444269</td>\n",
       "      <td>0.443519</td>\n",
       "      <td>0.316239</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.674506</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.290598</td>\n",
       "      <td>0.494683</td>\n",
       "      <td>0.403199</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.368182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6541</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973032</td>\n",
       "      <td>0.267241</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.520284</td>\n",
       "      <td>0.723092</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.520455</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6542</th>\n",
       "      <td>0.662037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132016</td>\n",
       "      <td>0.646552</td>\n",
       "      <td>0.367521</td>\n",
       "      <td>0.080740</td>\n",
       "      <td>0.409530</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.372727</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6543</th>\n",
       "      <td>0.509259</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.438696</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.724301</td>\n",
       "      <td>0.432189</td>\n",
       "      <td>0.521368</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.406818</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6544</th>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.671057</td>\n",
       "      <td>0.336207</td>\n",
       "      <td>0.247863</td>\n",
       "      <td>0.450965</td>\n",
       "      <td>0.240586</td>\n",
       "      <td>0.470085</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.459091</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6545</th>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.709313</td>\n",
       "      <td>0.836207</td>\n",
       "      <td>0.606838</td>\n",
       "      <td>0.632532</td>\n",
       "      <td>0.783739</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6546 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      accountlength  numbervmailmessages  totaldayminutes  totaldaycalls  \\\n",
       "0          0.384259             0.000000         0.537786       0.396552   \n",
       "1          0.459605             0.291667         0.541863       0.379310   \n",
       "2          0.532407             0.479167         0.732204       0.310345   \n",
       "3          0.680556             0.000000         0.661963       0.431034   \n",
       "4          0.277778             0.000000         0.674506       0.724138   \n",
       "...             ...                  ...              ...            ...   \n",
       "6541       0.375000             0.000000         0.973032       0.267241   \n",
       "6542       0.662037             0.000000         0.132016       0.646552   \n",
       "6543       0.509259             0.000000         0.438696       0.043103   \n",
       "6544       0.680556             0.000000         0.671057       0.336207   \n",
       "6545       0.296296             0.000000         0.709313       0.836207   \n",
       "\n",
       "      totalevecalls  totalevecharge  totalnightminutes  totalnightcalls  \\\n",
       "0          0.658120        0.890114           0.657114         0.316239   \n",
       "1          0.410256        0.119732           0.597468         0.666667   \n",
       "2          0.675214        0.287909           0.758747         0.529915   \n",
       "3          0.470085        0.444269           0.443519         0.316239   \n",
       "4          0.290598        0.494683           0.403199         0.333333   \n",
       "...             ...             ...                ...              ...   \n",
       "6541       0.666667        0.520284           0.723092         0.512821   \n",
       "6542       0.367521        0.080740           0.409530         0.487179   \n",
       "6543       0.094017        0.724301           0.432189         0.521368   \n",
       "6544       0.247863        0.450965           0.240586         0.470085   \n",
       "6545       0.606838        0.632532           0.783739         0.641026   \n",
       "\n",
       "      totalintlcalls  totalintlcharge  numbercustomerservicecalls  \n",
       "0                0.3         0.270455                         0.0  \n",
       "1                0.2         0.515909                         0.4  \n",
       "2                0.2         0.595455                         0.4  \n",
       "3                0.3         0.250000                         0.4  \n",
       "4                0.1         0.368182                         0.0  \n",
       "...              ...              ...                         ...  \n",
       "6541             0.5         0.520455                         0.0  \n",
       "6542             0.6         0.372727                         0.8  \n",
       "6543             0.1         0.406818                         0.4  \n",
       "6544             0.1         0.459091                         0.0  \n",
       "6545             0.4         0.127273                         0.8  \n",
       "\n",
       "[6546 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./../clean_data.csv\")\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=['float64']).columns\n",
    "\n",
    "x = df[numerical_columns]\n",
    "y = df['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Balancing data\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_oversampled, y_oversampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Display class distribution after oversampling\n",
    "print(\"\\nClass distribution after oversampling:\")\n",
    "print(pd.Series(y_oversampled).value_counts())\n",
    "\n",
    "# Apply RandomUnderSampler to address class imbalance\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_undersampled, y_undersampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Display class distribution after undersampling\n",
    "print(\"\\nClass distribution after undersampling:\")\n",
    "print(pd.Series(y_undersampled).value_counts())\n",
    "\n",
    "X_oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Accuracy: 0.9156118143459916\n",
      "\n",
      "Random Forest - Confusion Matrix:\n",
      " [[803  18]\n",
      " [ 62  65]]\n",
      "\n",
      "Random Forest - Recall: 0.5118110236220472\n",
      "Random Forest - Precision: 0.7831325301204819\n",
      "Random Forest - F1: 0.6190476190476191\n"
     ]
    }
   ],
   "source": [
    "# Random forest\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_oversampled, y_oversampled)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest - Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"\\nRandom Forest - Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"\\nRandom Forest - Recall:\", recall_score(y_test, y_pred_rf, pos_label='Yes'))\n",
    "print(\"Random Forest - Precision:\", precision_score(y_test, y_pred_rf, pos_label='Yes'))\n",
    "print(\"Random Forest - F1:\", f1_score(y_test, y_pred_rf, pos_label='Yes'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier - Accuracy: 0.8544303797468354\n",
      "\n",
      "GradientBoostingClassifier - Confusion Matrix:\n",
      " [[730  91]\n",
      " [ 47  80]]\n",
      "\n",
      "GradientBoostingClassifier - Recall: 0.6299212598425197\n",
      "GradientBoostingClassifier - Precision: 0.4678362573099415\n",
      "GradientBoostingClassifier - F1: 0.5369127516778524\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "gb_model.fit(X_oversampled, y_oversampled)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "print(\"GradientBoostingClassifier - Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(\"\\nGradientBoostingClassifier - Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_gb))\n",
    "print(\"\\nGradientBoostingClassifier - Recall:\", recall_score(y_test, y_pred_gb, pos_label='Yes'))\n",
    "print(\"GradientBoostingClassifier - Precision:\", precision_score(y_test, y_pred_gb, pos_label='Yes'))\n",
    "print(\"GradientBoostingClassifier - F1:\", f1_score(y_test, y_pred_gb, pos_label='Yes'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoostingClassifier - Accuracy: 0.8966244725738397\n",
      "\n",
      "HistGradientBoostingClassifier - Confusion Matrix:\n",
      " [[781  40]\n",
      " [ 58  69]]\n",
      "\n",
      "HistGradientBoostingClassifier - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          No       0.93      0.95      0.94       821\n",
      "         Yes       0.63      0.54      0.58       127\n",
      "\n",
      "    accuracy                           0.90       948\n",
      "   macro avg       0.78      0.75      0.76       948\n",
      "weighted avg       0.89      0.90      0.89       948\n",
      "\n",
      "\n",
      "HistGradientBoostingClassifier - Recall: 0.5433070866141733\n",
      "HistGradientBoostingClassifier - Precision: 0.6330275229357798\n",
      "HistGradientBoostingClassifier - F1: 0.5847457627118645\n"
     ]
    }
   ],
   "source": [
    "# HistGradientBoostingClassifier\n",
    "\n",
    "hgbc_model = HistGradientBoostingClassifier(random_state=42)\n",
    "hgbc_model.fit(X_oversampled, y_oversampled)\n",
    "y_pred_hgbc = hgbc_model.predict(X_test)\n",
    "\n",
    "print(\"HistGradientBoostingClassifier - Accuracy:\", accuracy_score(y_test, y_pred_hgbc))\n",
    "print(\"\\nHistGradientBoostingClassifier - Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_hgbc))\n",
    "print(\"\\nHistGradientBoostingClassifier - Classification Report:\\n\", classification_report(y_test, y_pred_hgbc))\n",
    "print(\"\\nHistGradientBoostingClassifier - Recall:\", recall_score(y_test, y_pred_hgbc, pos_label='Yes'))\n",
    "print(\"HistGradientBoostingClassifier - Precision:\", precision_score(y_test, y_pred_hgbc, pos_label='Yes'))\n",
    "print(\"HistGradientBoostingClassifier - F1:\", f1_score(y_test, y_pred_hgbc, pos_label='Yes'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores - Random Forest: [0.98350137 0.98945921 0.98716774]\n",
      "Random Forest Mean Accuracy: 0.9867094408799266\n",
      "Cross-Validation Scores - Gradient Boosting: [0.85059578 0.86480293 0.85701192]\n",
      "Gradient Boosting Mean Accuracy: 0.8574702108157654\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation\n",
    "\n",
    "cv_scores_rf = cross_val_score(rf_model, X_oversampled, y_oversampled, cv=3)\n",
    "cv_scores_gb = cross_val_score(gb_model, X_oversampled, y_oversampled, cv=3)\n",
    "\n",
    "print(\"Cross-Validation Scores - Random Forest:\", cv_scores_rf)\n",
    "print(\"Random Forest Mean Accuracy:\", np.mean(cv_scores_rf))\n",
    "print(\"Cross-Validation Scores - Gradient Boosting:\", cv_scores_gb)\n",
    "print(\"Gradient Boosting Mean Accuracy:\", np.mean(cv_scores_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter spaces for different classifiers\n",
    "param_grid_bagging = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0],\n",
    "    'bootstrap': [True, False],\n",
    "    'bootstrap_features': [True, False],\n",
    "    'base_estimator__criterion': ['gini', 'entropy'],\n",
    "    'base_estimator__max_depth': [None, 10, 20],\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None, 1, 2, 3],\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "param_grid_ada = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.5],\n",
    "    'algorithm': ['SAMME', 'SAMME.R'],\n",
    "}\n",
    "\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 0.5],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best Hyperparameters for Bagging: {'max_features': 0.5, 'max_samples': 1.0, 'n_estimators': 200}\n",
      "Best Bagging Accuracy: 0.8839662447257384\n",
      "Best Hyperparameters for Bagging (F1): {'max_features': 0.5, 'max_samples': 1.0, 'n_estimators': 100}\n",
      "Best Bagging F1 Score: 0.25675675675675674\n"
     ]
    }
   ],
   "source": [
    "# BaggingClassifier\n",
    "bagging_model = BaggingClassifier()\n",
    "grid_bagging = GridSearchCV(estimator=bagging_model, param_grid=param_grid_bagging, cv=5, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "grid_bagging.fit(X_imputed, y_oversampled)\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "y_pred_bagging = grid_bagging.best_estimator_.predict(X_test_imputed)\n",
    "acc_bagging = grid_bagging.best_estimator_.score(X_test_imputed, y_test)\n",
    "\n",
    "\n",
    "f1_scorer = make_scorer(f1_score, pos_label='Yes')\n",
    "grid_bagging_f1 = GridSearchCV(estimator=bagging_model, param_grid=param_grid_bagging, cv=5, n_jobs=-1, verbose=1, scoring=f1_scorer)\n",
    "grid_bagging_f1.fit(X_imputed, y_oversampled)\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "y_pred_bagging_f1 = grid_bagging_f1.best_estimator_.predict(X_test_imputed)\n",
    "\n",
    "# Calculate F1 score for the best model\n",
    "f1_bagging_best = f1_score(y_test, y_pred_bagging_f1, pos_label='Yes', average='binary')\n",
    "\n",
    "\n",
    "print(\"\\nBest Hyperparameters for Bagging:\", grid_bagging.best_params_)\n",
    "print(\"Best Bagging Accuracy:\", acc_bagging)\n",
    "print(\"Best Hyperparameters for Bagging (F1):\", grid_bagging_f1.best_params_)\n",
    "print(\"Best Bagging F1 Score:\", f1_bagging_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "\n",
      "Best Hyperparameters for RandomForest: {'max_depth': None, 'max_features': 1, 'n_estimators': 200}\n",
      "Best RandomForest Accuracy: 0.9008438818565401\n",
      "Best Hyperparameters for RandomForest (F1): {'max_depth': None, 'max_features': 1, 'n_estimators': 200}\n",
      "Best RadnomForest F1 Score: 0.46327683615819204\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "grid_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, cv=5, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "grid_rf.fit(X_imputed, y_oversampled)\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "y_pred_rf = grid_rf.best_estimator_.predict(X_test_imputed)\n",
    "acc_rf = grid_rf.best_estimator_.score(X_test_imputed, y_test)\n",
    "\n",
    "grid_rf_f1 = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, cv=5, n_jobs=-1, verbose=1, scoring=f1_scorer)\n",
    "grid_rf_f1.fit(X_imputed, y_oversampled)\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "y_pred_rf_f1 = grid_rf_f1.best_estimator_.predict(X_test_imputed)\n",
    "\n",
    "# Calculate F1 score for the best model\n",
    "f1_rf_best = f1_score(y_test, y_pred_rf_f1, pos_label='Yes', average='binary')\n",
    "\n",
    "print(\"\\nBest Hyperparameters for RandomForest:\", grid_rf.best_params_)\n",
    "print(\"Best RandomForest Accuracy:\", acc_rf)\n",
    "print(\"Best Hyperparameters for RandomForest (F1):\", grid_rf_f1.best_params_)\n",
    "print(\"Best RadnomForest F1 Score:\", f1_rf_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Best Hyperparameters for AdaBoost: {'n_estimators': 200}\n",
      "Best AdaBoost Accuracy: 0.7943037974683544\n",
      "Best Hyperparameters for AdaBoost (F1): {'n_estimators': 200}\n",
      "Best AdaBoost F1 Score: 0.44126074498567336\n"
     ]
    }
   ],
   "source": [
    "# AdaBoostClassifier\n",
    "ada_model = AdaBoostClassifier()\n",
    "grid_ada = GridSearchCV(estimator=ada_model, param_grid=param_grid_ada, cv=5, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "grid_ada.fit(X_imputed, y_oversampled)\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "y_pred_ada = grid_ada.best_estimator_.predict(X_test_imputed)\n",
    "acc_ada = grid_ada.best_estimator_.score(X_test_imputed, y_test)\n",
    "\n",
    "grid_ada_f1 = GridSearchCV(estimator=ada_model, param_grid=param_grid_ada, cv=5, n_jobs=-1, verbose=1, scoring=f1_scorer)\n",
    "grid_ada_f1.fit(X_imputed, y_oversampled)\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "y_pred_ada_f1 = grid_ada_f1.best_estimator_.predict(X_test_imputed)\n",
    "\n",
    "# Calculate F1 score for the best model\n",
    "f1_ada_best = f1_score(y_test, y_pred_ada_f1, pos_label='Yes', average='binary')\n",
    "\n",
    "\n",
    "print(\"Best Hyperparameters for AdaBoost:\", grid_ada.best_params_)\n",
    "print(\"Best AdaBoost Accuracy:\", acc_ada)\n",
    "print(\"Best Hyperparameters for AdaBoost (F1):\", grid_ada_f1.best_params_)\n",
    "print(\"Best AdaBoost F1 Score:\", f1_ada_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "Best Hyperparameters for GradientBoosting: {'learning_rate': 0.2, 'n_estimators': 200}\n",
      "Best GradientBoosting Accuracy: 0.8744725738396625\n",
      "Best Hyperparameters for GradientBoosting (F1): {'learning_rate': 0.2, 'n_estimators': 200}\n",
      "Best GradientBoosting F1 Score: 0.5703971119133574\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "gb_model = GradientBoostingClassifier()\n",
    "grid_gb = GridSearchCV(estimator=gb_model, param_grid=param_grid_gb, cv=5, n_jobs=-1, verbose=1, scoring='accuracy')\n",
    "grid_gb.fit(X_imputed, y_oversampled)\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "y_pred_gb= grid_gb.best_estimator_.predict(X_test_imputed)\n",
    "acc_gb = grid_gb.best_estimator_.score(X_test_imputed, y_test)\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "y_pred_gb = grid_gb.best_estimator_.predict(X_test_imputed)\n",
    "acc_gb = grid_gb.best_estimator_.score(X_test_imputed, y_test)\n",
    "\n",
    "f1_scorer = make_scorer(f1_score, pos_label='Yes')\n",
    "grid_gb_f1 = GridSearchCV(estimator=gb_model, param_grid=param_grid_gb, cv=5, n_jobs=-1, verbose=1, scoring=f1_scorer)\n",
    "grid_gb_f1.fit(X_imputed, y_oversampled)\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "y_pred_gb_f1 = grid_gb_f1.best_estimator_.predict(X_test_imputed)\n",
    "\n",
    "# Calculate F1 score for the best model\n",
    "f1_gb_best = f1_score(y_test, y_pred_gb_f1, pos_label='Yes', average='binary')\n",
    "\n",
    "print(\"Best Hyperparameters for GradientBoosting:\", grid_gb.best_params_)\n",
    "print(\"Best GradientBoosting Accuracy:\", acc_gb)\n",
    "print(\"Best Hyperparameters for GradientBoosting (F1):\", grid_gb_f1.best_params_)\n",
    "print(\"Best GradientBoosting F1 Score:\", f1_gb_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostingClassifier - Accuracy: 0.7943037974683544\n",
      "\n",
      "AdaBoostingClassifier - Confusion Matrix:\n",
      " [[667 154]\n",
      " [ 41  86]]\n",
      "\n",
      "AdaBoostingClassifier - Recall: 0.6771653543307087\n",
      "AdaBoostingClassifier - Precision: 0.35833333333333334\n",
      "AdaBoostingClassifier - F1: 0.4686648501362398\n",
      "BaggingClassifier - Accuracy: 0.9050632911392406\n",
      "\n",
      "BaggingClassifier - Confusion Matrix:\n",
      " [[795  26]\n",
      " [ 64  63]]\n",
      "\n",
      "BaggingClassifier - Recall: 0.49606299212598426\n",
      "BaggingClassifier - Precision: 0.7078651685393258\n",
      "BaggingClassifier - F1: 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "# AdaBoostingClassifier\n",
    "\n",
    "ada_model = AdaBoostClassifier(random_state=42)\n",
    "ada_model.fit(X_oversampled, y_oversampled)\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "\n",
    "print(\"AdaBoostingClassifier - Accuracy:\", accuracy_score(y_test, y_pred_ada))\n",
    "print(\"\\nAdaBoostingClassifier - Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_ada))\n",
    "print(\"\\nAdaBoostingClassifier - Recall:\", recall_score(y_test, y_pred_ada, pos_label='Yes'))\n",
    "print(\"AdaBoostingClassifier - Precision:\", precision_score(y_test, y_pred_ada, pos_label='Yes'))\n",
    "print(\"AdaBoostingClassifier - F1:\", f1_score(y_test, y_pred_ada, pos_label='Yes'))\n",
    "\n",
    "\n",
    "# BaggingClassifier\n",
    "bagging_model = BaggingClassifier(random_state=42)\n",
    "bagging_model.fit(X_oversampled, y_oversampled)\n",
    "y_pred_bagging = bagging_model.predict(X_test)\n",
    "\n",
    "print(\"BaggingClassifier - Accuracy:\", accuracy_score(y_test, y_pred_bagging))\n",
    "print(\"\\nBaggingClassifier - Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_bagging))\n",
    "print(\"\\nBaggingClassifier - Recall:\", recall_score(y_test, y_pred_bagging, pos_label='Yes'))\n",
    "print(\"BaggingClassifier - Precision:\", precision_score(y_test, y_pred_bagging, pos_label='Yes'))\n",
    "print(\"BaggingClassifier - F1:\", f1_score(y_test, y_pred_bagging, pos_label='Yes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit ('sbin')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e1d9a8909477db77738c33245c29c7265277ef753467dede8cf3f814cde494e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
