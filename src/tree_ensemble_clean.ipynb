{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pre-processing\n",
    "df = pd.read_csv(\"./../processed_data.csv\")\n",
    "\n",
    "X = df.drop('churn', axis=1)\n",
    "y = df['churn']\n",
    "\n",
    "# ros = RandomOverSampler(random_state=42)\n",
    "# X_balanced, y_balanced = ros.fit_resample(X, y)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.replace({'yes': 1, 'no': 0}, inplace=True)\n",
    "X_test.replace({'yes': 1, 'no': 0}, inplace=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Imputer - Accuracy: 0.872791519434629\n",
      "\n",
      "Random Forest with Imputer - Confusion Matrix:\n",
      " [[126  14]\n",
      " [ 22 121]]\n",
      "\n",
      "Random Forest with Imputer - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88       140\n",
      "           1       0.90      0.85      0.87       143\n",
      "\n",
      "    accuracy                           0.87       283\n",
      "   macro avg       0.87      0.87      0.87       283\n",
      "weighted avg       0.87      0.87      0.87       283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random forest\n",
    "\n",
    "rf_model_with_imputer = make_pipeline(SimpleImputer(strategy='mean'), RandomForestClassifier(random_state=42))\n",
    "rf_model_with_imputer.fit(X_train, y_train_encoded)\n",
    "y_pred_rf_imputed = rf_model_with_imputer.predict(X_test)\n",
    "\n",
    "print(\"Random Forest with Imputer - Accuracy:\", accuracy_score(y_test_encoded, y_pred_rf_imputed))\n",
    "print(\"\\nRandom Forest with Imputer - Confusion Matrix:\\n\", confusion_matrix(y_test_encoded, y_pred_rf_imputed))\n",
    "print(\"\\nRandom Forest with Imputer - Classification Report:\\n\", classification_report(y_test_encoded, y_pred_rf_imputed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier with Imputer - Accuracy: 0.8798586572438163\n",
      "\n",
      "GradientBoostingClassifier with Imputer - Confusion Matrix:\n",
      " [[128  12]\n",
      " [ 22 121]]\n",
      "\n",
      "GradientBoostingClassifier with Imputer - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       140\n",
      "           1       0.91      0.85      0.88       143\n",
      "\n",
      "    accuracy                           0.88       283\n",
      "   macro avg       0.88      0.88      0.88       283\n",
      "weighted avg       0.88      0.88      0.88       283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "\n",
    "gb_model_with_imputer = make_pipeline(SimpleImputer(strategy='mean'), GradientBoostingClassifier(random_state=42))\n",
    "gb_model_with_imputer.fit(X_train, y_train_encoded)\n",
    "y_pred_gb_imputed = gb_model_with_imputer.predict(X_test)\n",
    "\n",
    "print(\"GradientBoostingClassifier with Imputer - Accuracy:\", accuracy_score(y_test_encoded, y_pred_gb_imputed))\n",
    "print(\"\\nGradientBoostingClassifier with Imputer - Confusion Matrix:\\n\", confusion_matrix(y_test_encoded, y_pred_gb_imputed))\n",
    "print(\"\\nGradientBoostingClassifier with Imputer - Classification Report:\\n\", classification_report(y_test_encoded, y_pred_gb_imputed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoostingClassifier - Accuracy: 0.8621908127208481\n",
      "\n",
      "HistGradientBoostingClassifier - Confusion Matrix:\n",
      " [[125  15]\n",
      " [ 24 119]]\n",
      "\n",
      "HistGradientBoostingClassifier - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.87       140\n",
      "           1       0.89      0.83      0.86       143\n",
      "\n",
      "    accuracy                           0.86       283\n",
      "   macro avg       0.86      0.86      0.86       283\n",
      "weighted avg       0.86      0.86      0.86       283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HistGradientBoostingClassifier\n",
    "\n",
    "hgbc_model = HistGradientBoostingClassifier(random_state=42)\n",
    "hgbc_model.fit(X_train, y_train_encoded)\n",
    "y_pred_hgbc = hgbc_model.predict(X_test)\n",
    "\n",
    "print(\"HistGradientBoostingClassifier - Accuracy:\", accuracy_score(y_test_encoded, y_pred_hgbc))\n",
    "print(\"\\nHistGradientBoostingClassifier - Confusion Matrix:\\n\", confusion_matrix(y_test_encoded, y_pred_hgbc))\n",
    "print(\"\\nHistGradientBoostingClassifier - Classification Report:\\n\", classification_report(y_test_encoded, y_pred_hgbc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores - Random Forest: [0.83819629 0.8806366  0.90185676]\n",
      "Random Forest Mean Accuracy: 0.8735632183908045\n",
      "Cross-Validation Scores - Gradient Boosting: [0.86472149 0.87533156 0.88859416]\n",
      "Gradient Boosting Mean Accuracy: 0.8762157382847038\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation\n",
    "\n",
    "cv_scores_rf = cross_val_score(rf_model_with_imputer, X_train, y_train_encoded, cv=3)\n",
    "cv_scores_gb = cross_val_score(gb_model_with_imputer, X_train, y_train_encoded, cv=3)\n",
    "\n",
    "print(\"Cross-Validation Scores - Random Forest:\", cv_scores_rf)\n",
    "print(\"Random Forest Mean Accuracy:\", np.mean(cv_scores_rf))\n",
    "print(\"Cross-Validation Scores - Gradient Boosting:\", cv_scores_gb)\n",
    "print(\"Gradient Boosting Mean Accuracy:\", np.mean(cv_scores_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature importance\n",
    "# feature_importance = rf_model.feature_importances_\n",
    "\n",
    "# # Visualizing feature importance\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.barh(X.columns, feature_importance)\n",
    "# plt.title(\"Random Forest - Feature Importance\")\n",
    "# plt.xlabel(\"Importance\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter spaces for different classifiers\n",
    "param_grid_bagging = {\n",
    "    'baggingclassifier__n_estimators': [50, 100, 200],\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'randomforestclassifier__n_estimators': [50, 100, 200],\n",
    "    'randomforestclassifier__max_depth': [None, 10, 20],  \n",
    "    'randomforestclassifier__max_features': ['sqrt', 'log2', None, 1, 2, 3],  \n",
    "}\n",
    "\n",
    "param_grid_ada = {\n",
    "    'adaboostclassifier__n_estimators': [50, 100, 200],\n",
    "}\n",
    "\n",
    "param_grid_gb = {\n",
    "    'gradientboostingclassifier__n_estimators': [50, 100, 200],\n",
    "    'gradientboostingclassifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for Bagging: {'baggingclassifier__n_estimators': 200}\n",
      "Best Bagging Accuracy: 0.8551236749116607\n"
     ]
    }
   ],
   "source": [
    "# BaggingClassifier\n",
    "bagging_model = BaggingClassifier()\n",
    "bagging_model_with_imputer = make_pipeline(SimpleImputer(strategy='mean'), bagging_model)\n",
    "grid_search_bagging = GridSearchCV(bagging_model_with_imputer, param_grid_bagging, cv=5)\n",
    "grid_search_bagging.fit(X_imputed, y_train_encoded)\n",
    "\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "y_pred_bagging = grid_search_bagging.best_estimator_.predict(X_test_imputed)\n",
    "acc_bagging = grid_search_bagging.best_estimator_.score(X_test_imputed, y_test_encoded)\n",
    "\n",
    "print(\"Best Hyperparameters for Bagging:\", grid_search_bagging.best_params_)\n",
    "print(\"Best Bagging Accuracy:\", acc_bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for RandomForest: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__max_features': None, 'randomforestclassifier__n_estimators': 200}\n",
      "Best RandomForest Accuracy: 0.8515901060070671\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model_with_imputer = make_pipeline(SimpleImputer(strategy='mean'), rf_model)\n",
    "grid_search_rf = GridSearchCV(rf_model_with_imputer, param_grid_rf, cv=5)\n",
    "grid_search_rf.fit(X_imputed, y_train_encoded)\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "y_pred_rf = grid_search_rf.best_estimator_.predict(X_test_imputed)\n",
    "acc_rf = grid_search_rf.best_estimator_.score(X_test_imputed, y_test_encoded)\n",
    "\n",
    "print(\"Best Hyperparameters for RandomForest:\", grid_search_rf.best_params_)\n",
    "print(\"Best RandomForest Accuracy:\", acc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for AdaBoost: {'adaboostclassifier__n_estimators': 50}\n",
      "Best AdaBoost Accuracy: 0.7950530035335689\n"
     ]
    }
   ],
   "source": [
    "# AdaBoostClassifier\n",
    "ada_model = AdaBoostClassifier()\n",
    "ada_model_with_imputer = make_pipeline(SimpleImputer(strategy='mean'), ada_model)\n",
    "grid_search_ada = GridSearchCV(ada_model_with_imputer, param_grid_ada, cv=5)\n",
    "grid_search_ada.fit(X_imputed, y_train_encoded)\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "y_pred_ada = grid_search_ada.best_estimator_.predict(X_test_imputed)\n",
    "acc_ada = grid_search_ada.best_estimator_.score(X_test_imputed, y_test_encoded)\n",
    "\n",
    "print(\"Best Hyperparameters for AdaBoost:\", grid_search_ada.best_params_)\n",
    "print(\"Best AdaBoost Accuracy:\", acc_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for GradientBoosting: {'gradientboostingclassifier__learning_rate': 0.1, 'gradientboostingclassifier__n_estimators': 100}\n",
      "Best GradientBoosting Accuracy: 0.8798586572438163\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "gb_model = GradientBoostingClassifier()\n",
    "gb_model_with_imputer = make_pipeline(SimpleImputer(strategy='mean'), gb_model)\n",
    "grid_search_gb = GridSearchCV(gb_model_with_imputer, param_grid_gb, cv=5)\n",
    "grid_search_gb.fit(X_imputed, y_train_encoded)\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "y_pred_gb= grid_search_gb.best_estimator_.predict(X_test_imputed)\n",
    "acc_gb = grid_search_gb.best_estimator_.score(X_test_imputed, y_test_encoded)\n",
    "\n",
    "print(\"Best Hyperparameters for GradientBoosting:\", grid_search_gb.best_params_)\n",
    "print(\"Best GradientBoosting Accuracy:\", acc_gb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit ('sbin')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e1d9a8909477db77738c33245c29c7265277ef753467dede8cf3f814cde494e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
