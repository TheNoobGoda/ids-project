{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pre-processing\n",
    "df = pd.read_csv(\"./../churn_data.csv\")\n",
    "\n",
    "X = df.drop('churn', axis=1)\n",
    "y = df['churn']\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_balanced, y_balanced = ros.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.replace({'yes': 1, 'no': 0}, inplace=True)\n",
    "X_test.replace({'yes': 1, 'no': 0}, inplace=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with Imputer - Accuracy: 0.9918509895227008\n",
      "\n",
      "Random Forest with Imputer - Confusion Matrix:\n",
      " [[831  13]\n",
      " [  1 873]]\n",
      "\n",
      "Random Forest with Imputer - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       844\n",
      "           1       0.99      1.00      0.99       874\n",
      "\n",
      "    accuracy                           0.99      1718\n",
      "   macro avg       0.99      0.99      0.99      1718\n",
      "weighted avg       0.99      0.99      0.99      1718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random forest\n",
    "\n",
    "rf_model_with_imputer = make_pipeline(SimpleImputer(strategy='mean'), RandomForestClassifier(random_state=42))\n",
    "rf_model_with_imputer.fit(X_train, y_train_encoded)\n",
    "y_pred_rf_imputed = rf_model_with_imputer.predict(X_test)\n",
    "\n",
    "print(\"Random Forest with Imputer - Accuracy:\", accuracy_score(y_test_encoded, y_pred_rf_imputed))\n",
    "print(\"\\nRandom Forest with Imputer - Confusion Matrix:\\n\", confusion_matrix(y_test_encoded, y_pred_rf_imputed))\n",
    "print(\"\\nRandom Forest with Imputer - Classification Report:\\n\", classification_report(y_test_encoded, y_pred_rf_imputed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier with Imputer - Accuracy: 0.9010477299185099\n",
      "\n",
      "GradientBoostingClassifier with Imputer - Confusion Matrix:\n",
      " [[796  48]\n",
      " [122 752]]\n",
      "\n",
      "GradientBoostingClassifier with Imputer - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90       844\n",
      "           1       0.94      0.86      0.90       874\n",
      "\n",
      "    accuracy                           0.90      1718\n",
      "   macro avg       0.90      0.90      0.90      1718\n",
      "weighted avg       0.90      0.90      0.90      1718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "\n",
    "gb_model_with_imputer = make_pipeline(SimpleImputer(strategy='mean'), GradientBoostingClassifier(random_state=42))\n",
    "gb_model_with_imputer.fit(X_train, y_train_encoded)\n",
    "y_pred_gb_imputed = gb_model_with_imputer.predict(X_test)\n",
    "\n",
    "print(\"GradientBoostingClassifier with Imputer - Accuracy:\", accuracy_score(y_test_encoded, y_pred_gb_imputed))\n",
    "print(\"\\nGradientBoostingClassifier with Imputer - Confusion Matrix:\\n\", confusion_matrix(y_test_encoded, y_pred_gb_imputed))\n",
    "print(\"\\nGradientBoostingClassifier with Imputer - Classification Report:\\n\", classification_report(y_test_encoded, y_pred_gb_imputed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoostingClassifier - Accuracy: 0.9848661233993015\n",
      "\n",
      "HistGradientBoostingClassifier - Confusion Matrix:\n",
      " [[822  22]\n",
      " [  4 870]]\n",
      "\n",
      "HistGradientBoostingClassifier - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       844\n",
      "           1       0.98      1.00      0.99       874\n",
      "\n",
      "    accuracy                           0.98      1718\n",
      "   macro avg       0.99      0.98      0.98      1718\n",
      "weighted avg       0.99      0.98      0.98      1718\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# HistGradientBoostingClassifier\n",
    "\n",
    "hgbc_model = HistGradientBoostingClassifier(random_state=42)\n",
    "hgbc_model.fit(X_train, y_train_encoded)\n",
    "y_pred_hgbc = hgbc_model.predict(X_test)\n",
    "\n",
    "print(\"HistGradientBoostingClassifier - Accuracy:\", accuracy_score(y_test_encoded, y_pred_hgbc))\n",
    "print(\"\\nHistGradientBoostingClassifier - Confusion Matrix:\\n\", confusion_matrix(y_test_encoded, y_pred_hgbc))\n",
    "print(\"\\nHistGradientBoostingClassifier - Classification Report:\\n\", classification_report(y_test_encoded, y_pred_hgbc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores - Random Forest: [0.98995633 0.98383574 0.98296199]\n",
      "Random Forest Mean Accuracy: 0.9855846867144491\n",
      "Cross-Validation Scores - Gradient Boosting: [0.90742358 0.90782001 0.90345129]\n",
      "Gradient Boosting Mean Accuracy: 0.9062316260986186\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation\n",
    "\n",
    "cv_scores_rf = cross_val_score(rf_model_with_imputer, X_train, y_train_encoded, cv=3)\n",
    "cv_scores_gb = cross_val_score(gb_model_with_imputer, X_train, y_train_encoded, cv=3)\n",
    "\n",
    "print(\"Cross-Validation Scores - Random Forest:\", cv_scores_rf)\n",
    "print(\"Random Forest Mean Accuracy:\", np.mean(cv_scores_rf))\n",
    "print(\"Cross-Validation Scores - Gradient Boosting:\", cv_scores_gb)\n",
    "print(\"Gradient Boosting Mean Accuracy:\", np.mean(cv_scores_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature importance\n",
    "# feature_importance = rf_model.feature_importances_\n",
    "\n",
    "# # Visualizing feature importance\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.barh(X.columns, feature_importance)\n",
    "# plt.title(\"Random Forest - Feature Importance\")\n",
    "# plt.xlabel(\"Importance\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter spaces for different classifiers\n",
    "param_grid_bagging = {\n",
    "    'baggingclassifier__n_estimators': [50, 100, 200],\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'randomforestclassifier__n_estimators': [50, 100, 200],\n",
    "    'randomforestclassifier__max_depth': [None, 10, 20],  \n",
    "    'randomforestclassifier__max_features': ['sqrt', 'log2', None, 1, 2, 3],  \n",
    "}\n",
    "\n",
    "param_grid_ada = {\n",
    "    'adaboostclassifier__n_estimators': [50, 100, 200],\n",
    "}\n",
    "\n",
    "param_grid_gb = {\n",
    "    'gradientboostingclassifier__n_estimators': [50, 100, 200],\n",
    "    'gradientboostingclassifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for Bagging: {'baggingclassifier__n_estimators': 200}\n",
      "Best Bagging Accuracy: 0.989522700814901\n"
     ]
    }
   ],
   "source": [
    "# BaggingClassifier\n",
    "bagging_model = BaggingClassifier()\n",
    "bagging_model_with_imputer = make_pipeline(SimpleImputer(strategy='mean'), bagging_model)\n",
    "grid_search_bagging = GridSearchCV(bagging_model_with_imputer, param_grid_bagging, cv=5)\n",
    "grid_search_bagging.fit(X_imputed, y_train_encoded)\n",
    "\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "y_pred_bagging = grid_search_bagging.best_estimator_.predict(X_test_imputed)\n",
    "acc_bagging = grid_search_bagging.best_estimator_.score(X_test_imputed, y_test_encoded)\n",
    "\n",
    "print(\"Best Hyperparameters for Bagging:\", grid_search_bagging.best_params_)\n",
    "print(\"Best Bagging Accuracy:\", acc_bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for RandomForest: {'randomforestclassifier__max_depth': None, 'randomforestclassifier__max_features': 1, 'randomforestclassifier__n_estimators': 100}\n",
      "Best RandomForest Accuracy: 0.9976717112922002\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model_with_imputer = make_pipeline(SimpleImputer(strategy='mean'), rf_model)\n",
    "grid_search_rf = GridSearchCV(rf_model_with_imputer, param_grid_rf, cv=5)\n",
    "grid_search_rf.fit(X_imputed, y_train_encoded)\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "y_pred_rf = grid_search_rf.best_estimator_.predict(X_test_imputed)\n",
    "acc_rf = grid_search_rf.best_estimator_.score(X_test_imputed, y_test_encoded)\n",
    "\n",
    "print(\"Best Hyperparameters for RandomForest:\", grid_search_rf.best_params_)\n",
    "print(\"Best RandomForest Accuracy:\", acc_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for AdaBoost: {'adaboostclassifier__n_estimators': 200}\n",
      "Best AdaBoost Accuracy: 0.8573923166472642\n"
     ]
    }
   ],
   "source": [
    "# AdaBoostClassifier\n",
    "ada_model = AdaBoostClassifier()\n",
    "ada_model_with_imputer = make_pipeline(SimpleImputer(strategy='mean'), ada_model)\n",
    "grid_search_ada = GridSearchCV(ada_model_with_imputer, param_grid_ada, cv=5)\n",
    "grid_search_ada.fit(X_imputed, y_train_encoded)\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "y_pred_ada = grid_search_ada.best_estimator_.predict(X_test_imputed)\n",
    "acc_ada = grid_search_ada.best_estimator_.score(X_test_imputed, y_test_encoded)\n",
    "\n",
    "print(\"Best Hyperparameters for AdaBoost:\", grid_search_ada.best_params_)\n",
    "print(\"Best AdaBoost Accuracy:\", acc_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for GradientBoosting: {'gradientboostingclassifier__learning_rate': 0.2, 'gradientboostingclassifier__n_estimators': 200}\n",
      "Best GradientBoosting Accuracy: 0.9575087310826542\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingClassifier\n",
    "gb_model = GradientBoostingClassifier()\n",
    "gb_model_with_imputer = make_pipeline(SimpleImputer(strategy='mean'), gb_model)\n",
    "grid_search_gb = GridSearchCV(gb_model_with_imputer, param_grid_gb, cv=5)\n",
    "grid_search_gb.fit(X_imputed, y_train_encoded)\n",
    "\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "y_pred_gb= grid_search_gb.best_estimator_.predict(X_test_imputed)\n",
    "acc_gb = grid_search_gb.best_estimator_.score(X_test_imputed, y_test_encoded)\n",
    "\n",
    "print(\"Best Hyperparameters for GradientBoosting:\", grid_search_gb.best_params_)\n",
    "print(\"Best GradientBoosting Accuracy:\", acc_gb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit ('sbin')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e1d9a8909477db77738c33245c29c7265277ef753467dede8cf3f814cde494e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
