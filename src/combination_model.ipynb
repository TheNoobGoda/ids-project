{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results= [['name','accuracy','recall','prec','f1','mean']]\n",
    "def evaluate_model(model,name,X_test,y_test,dec_number):\n",
    "    yhat = model.predict(X_test)\n",
    "\n",
    "    acc = round(sklearn.metrics.accuracy_score(y_test,yhat),dec_number)\n",
    "    recall = round(sklearn.metrics.recall_score(y_test,yhat,pos_label='Yes'),dec_number)\n",
    "    prec = round(sklearn.metrics.precision_score(y_test,yhat,pos_label='Yes'),dec_number)\n",
    "    f1 = round(sklearn.metrics.f1_score(y_test,yhat,pos_label='Yes'),dec_number)\n",
    "    mean = round((acc+recall+prec+f1)/4,dec_number)\n",
    "\n",
    "    results.append([name,acc,recall,prec,f1,mean])\n",
    "    \n",
    "    \n",
    "def print_results(results):\n",
    "    # Print each row\n",
    "    for row in results:\n",
    "        row_str = \" | \".join(str(element) for element in row)\n",
    "        print(row_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution after oversampling:\n",
      "churn\n",
      "No     3281\n",
      "Yes    3281\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution after undersampling:\n",
      "churn\n",
      "No     509\n",
      "Yes    509\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../clean_data.csv')\n",
    "\n",
    "numerical_columns = df.select_dtypes(include=['float64','int']).columns\n",
    "\n",
    "x = df[numerical_columns]\n",
    "y = df['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_oversampled, y_oversampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Display class distribution after oversampling\n",
    "print(\"\\nClass distribution after oversampling:\")\n",
    "print(pd.Series(y_oversampled).value_counts())\n",
    "\n",
    "# Apply RandomUnderSampler to address class imbalance\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_undersampled, y_undersampled = rus.fit_resample(X_train, y_train)\n",
    "\n",
    "# Display class distribution after undersampling\n",
    "print(\"\\nClass distribution after undersampling:\")\n",
    "print(pd.Series(y_undersampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel='rbf', C=10, gamma=1, degree=2, probability=True)\n",
    "nn_accuracy = MLPClassifier(activation= 'relu', alpha= 0.001, batch_size= 32, hidden_layer_sizes= (50, 50), learning_rate= 'adaptive', max_iter= 9999999999, solver= 'adam') \n",
    "rf_model = RandomForestClassifier(bootstrap=False, max_depth=30, max_features=1, min_samples_split=5, n_estimators=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model combination\n",
    "\n",
    "Now we will analyze if combining the results of models can give us any improvement in performence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [('svm',svm),('nn',nn_accuracy),('rf',rf_model)]\n",
    "\n",
    "hard_voting_clf = VotingClassifier(models, voting='hard')\n",
    "\n",
    "soft_voting_clf = VotingClassifier(models, voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_voting_clf.fit(X_oversampled,y_oversampled)\n",
    "\n",
    "evaluate_model(hard_voting_clf,'hard_voting_clf',X_test,y_test,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_voting_clf.fit(X_oversampled,y_oversampled)\n",
    "evaluate_model(soft_voting_clf,'soft_voting_clf',X_test,y_test,3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name | accuracy | recall | prec | f1 | mean\n",
      "hard_voting_clf | 0.944 | 0.723 | 0.868 | 0.789 | 0.831\n",
      "soft_voting_clf | 0.941 | 0.73 | 0.84 | 0.781 | 0.823\n"
     ]
    }
   ],
   "source": [
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the results we can see that combining the results of our best performing models does improve the our results\n",
    "\n",
    "|name | accuracy | recall | prec | f1 | mean|\n",
    "|----|-----|----|----|----|----|\n",
    "|svm | 0.926 | 0.583 | 0.813 | 0.679 | 0.75|\n",
    "|nn_accuracy | 0.925 | 0.685 | 0.737 | 0.71 | 0.764|\n",
    "|rf_model | 0.912 | 0.354 | 0.978 | 0.52 | 0.691|\n",
    "|hard_voting_clf | 0.944 | 0.723 | 0.868 | 0.789 | 0.831|\n",
    "|soft_voting_clf | 0.941 | 0.73 | 0.84 | 0.781 | 0.823|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there is an improvement of over 6% from our previously best model and every metric improved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
